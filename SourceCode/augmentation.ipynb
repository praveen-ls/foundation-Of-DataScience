{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdeea5e4-88a2-48d3-ba83-087dcd067a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting collapsed_building from 408 to 3200 images...\n",
      "Augmenting fire from 416 to 3200 images...\n",
      "Augmenting flooded_areas from 420 to 3200 images...\n",
      "Skipping normal, already has 3512 images.\n",
      "Augmenting traffic_incident from 388 to 3200 images...\n",
      "✅ Augmentation completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "\n",
    "# Define paths\n",
    "original_data_dir = 'C:\\\\FDS\\\\AIDER'  \n",
    "train_path = \"C:\\\\FDS\\\\Project\\\\train\"\n",
    "test_path = \"C:\\\\FDS\\\\Project\\\\test\"\n",
    "TARGET_SIZE = (256, 256)  \n",
    "\n",
    "# Split into Train and Test (with resizing)\n",
    "os.makedirs(train_path, exist_ok=True)\n",
    "os.makedirs(test_path, exist_ok=True)\n",
    "\n",
    "for class_name in os.listdir(original_data_dir):\n",
    "    class_path = os.path.join(original_data_dir, class_name)\n",
    "    images = glob.glob(os.path.join(class_path, \"*.jpg\"))  \n",
    "    train_images, test_images = train_test_split(images, test_size=0.2, random_state=42)\n",
    "\n",
    "    os.makedirs(os.path.join(train_path, class_name), exist_ok=True)\n",
    "    os.makedirs(os.path.join(test_path, class_name), exist_ok=True)\n",
    "\n",
    "    for img_path in train_images:\n",
    "        img = load_img(img_path)\n",
    "        img = img.resize(TARGET_SIZE)  \n",
    "        img.save(os.path.join(train_path, class_name, os.path.basename(img_path)))\n",
    "\n",
    "    for img_path in test_images:\n",
    "        img = load_img(img_path)\n",
    "        img = img.resize(TARGET_SIZE)  \n",
    "        img.save(os.path.join(test_path, class_name, os.path.basename(img_path)))\n",
    "import os\n",
    "import glob\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "\n",
    "def augment_images(class_name, target_count):\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=30, width_shift_range=0.2, height_shift_range=0.2, \n",
    "        shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode=\"nearest\"\n",
    "    )\n",
    "\n",
    "    class_train_path = os.path.join(train_path, class_name)\n",
    "    images = glob.glob(os.path.join(class_train_path, \"*.jpg\"))\n",
    "\n",
    "    current_count = len(images)\n",
    "    if current_count >= target_count:\n",
    "        print(f\"Skipping {class_name}, already has {current_count} images.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Augmenting {class_name} from {current_count} to {target_count} images...\")\n",
    "\n",
    "    generated = 0  \n",
    "    images_per_original = max(1, (target_count - current_count) // current_count) \n",
    "\n",
    "    for img_path in images:\n",
    "        if current_count + generated >= target_count:\n",
    "            break \n",
    "\n",
    "        img = load_img(img_path)\n",
    "        img = img.resize(TARGET_SIZE)  \n",
    "        img = img_to_array(img)\n",
    "        img = img.reshape((1,) + img.shape)\n",
    "\n",
    "        save_prefix = os.path.basename(img_path).split(\".\")[0] + \"_aug\"\n",
    "        i = 0\n",
    "        for batch in datagen.flow(img, batch_size=1, save_to_dir=class_train_path, \n",
    "                                  save_prefix=save_prefix, save_format=\"jpg\"):\n",
    "            generated += 1\n",
    "            i += 1\n",
    "            if current_count + generated >= target_count or i >= images_per_original:\n",
    "                break  \n",
    "\n",
    "# Apply augmentation to all classes\n",
    "for class_name in os.listdir(train_path):\n",
    "    augment_images(class_name, 3200)\n",
    "\n",
    "print(\"✅ Augmentation completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea4a026-e532-47c0-8860-f1d598ddf943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6df4e3-a11e-4e10-903e-94ad53013026",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
